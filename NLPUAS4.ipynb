{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading data train.01.jsonl: 100%|██████████| 14262/14262 [00:01<00:00, 8470.95it/s] \n",
      "Altering json data train.01.jsonl: 100%|██████████| 14262/14262 [00:00<00:00, 24578.51it/s]\n",
      "Loading data train.02.jsonl: 100%|██████████| 14263/14263 [00:01<00:00, 8693.85it/s]\n",
      "Altering json data train.02.jsonl: 100%|██████████| 14263/14263 [00:00<00:00, 24536.92it/s]\n",
      "Loading data train.03.jsonl: 100%|██████████| 14290/14290 [00:01<00:00, 8883.77it/s]\n",
      "Altering json data train.03.jsonl: 100%|██████████| 14290/14290 [00:00<00:00, 24212.32it/s]\n",
      "Loading data train.04.jsonl: 100%|██████████| 14272/14272 [00:01<00:00, 8110.60it/s]\n",
      "Altering json data train.04.jsonl: 100%|██████████| 14272/14272 [00:00<00:00, 24476.74it/s]\n",
      "Loading data train.05.jsonl: 100%|██████████| 14266/14266 [00:01<00:00, 8163.05it/s]\n",
      "Altering json data train.05.jsonl: 100%|██████████| 14266/14266 [00:00<00:00, 23892.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>gold_labels</th>\n",
       "      <th>id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>source</th>\n",
       "      <th>source_url</th>\n",
       "      <th>summary</th>\n",
       "      <th>news_text</th>\n",
       "      <th>num_of_paragraphs</th>\n",
       "      <th>summary_text</th>\n",
       "      <th>num_of_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [false, true], \"1\": [true, true], \"2\": [...</td>\n",
       "      <td>1501893029-lula-kamal-dokter-ryan-thamrin-saki...</td>\n",
       "      <td>{\"0\": [\"Jakarta , CNN Indonesia - - Dokter Rya...</td>\n",
       "      <td>cnn indonesia</td>\n",
       "      <td>https://www.cnnindonesia.com/hiburan/201708041...</td>\n",
       "      <td>{\"0\": \"Dokter Lula Kamal yang merupakan selebr...</td>\n",
       "      <td>Jakarta , CNN Indonesia - - Dokter Ryan Thamri...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dokter Lula Kamal yang merupakan selebriti sek...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teknologi</td>\n",
       "      <td>{\"0\": [false, false, false, false], \"1\": [fals...</td>\n",
       "      <td>1509072914-dua-smartphone-zenfone-baru-tawarka...</td>\n",
       "      <td>{\"0\": [\"Selfie ialah salah satu tema terpanas ...</td>\n",
       "      <td>dailysocial.id</td>\n",
       "      <td>https://dailysocial.id/post/dua-smartphone-zen...</td>\n",
       "      <td>{\"0\": \"Asus memperkenalkan \\u00a0 ZenFone gene...</td>\n",
       "      <td>Selfie ialah salah satu tema terpanas di kalan...</td>\n",
       "      <td>14</td>\n",
       "      <td>Asus memperkenalkan   ZenFone generasi keempat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hiburan</td>\n",
       "      <td>{\"0\": [true], \"1\": [true], \"2\": [false, false]...</td>\n",
       "      <td>1510613677-songsong-visit-2020-bengkulu-perkua...</td>\n",
       "      <td>{\"0\": [\"Jakarta , CNN Indonesia - - Dinas Pari...</td>\n",
       "      <td>cnn indonesia</td>\n",
       "      <td>https://www.cnnindonesia.com/gaya-hidup/201711...</td>\n",
       "      <td>{\"0\": \"Dinas Pariwisata Provinsi Bengkulu kemb...</td>\n",
       "      <td>Jakarta , CNN Indonesia - - Dinas Pariwisata P...</td>\n",
       "      <td>21</td>\n",
       "      <td>Dinas Pariwisata Provinsi Bengkulu kembali men...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [true, true], \"1\": [false, false, false]...</td>\n",
       "      <td>1502706803-icw-ada-kejanggalan-atas-tewasnya-s...</td>\n",
       "      <td>{\"0\": [\"Merdeka.com - Indonesia Corruption Wat...</td>\n",
       "      <td>merdeka</td>\n",
       "      <td>https://www.merdeka.com/peristiwa/icw-merasa-a...</td>\n",
       "      <td>{\"0\": \"Indonesia Corruption Watch ( ICW ) memi...</td>\n",
       "      <td>Merdeka.com - Indonesia Corruption Watch ( ICW...</td>\n",
       "      <td>5</td>\n",
       "      <td>Indonesia Corruption Watch ( ICW ) meminta Kom...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [false, true], \"1\": [true, true, true], ...</td>\n",
       "      <td>1503039338-pembagian-sepeda-usai-upacara-penur...</td>\n",
       "      <td>{\"0\": [\"Merdeka.com - Presiden Joko Widodo ( J...</td>\n",
       "      <td>merdeka</td>\n",
       "      <td>https://www.merdeka.com/peristiwa/usai-upacara...</td>\n",
       "      <td>{\"0\": \"Jokowi memimpin upacara penurunan bende...</td>\n",
       "      <td>Merdeka.com - Presiden Joko Widodo ( Jokowi ) ...</td>\n",
       "      <td>7</td>\n",
       "      <td>Jokowi memimpin upacara penurunan bendera . Us...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                        gold_labels  \\\n",
       "0  tajuk utama  {\"0\": [false, true], \"1\": [true, true], \"2\": [...   \n",
       "1    teknologi  {\"0\": [false, false, false, false], \"1\": [fals...   \n",
       "2      hiburan  {\"0\": [true], \"1\": [true], \"2\": [false, false]...   \n",
       "3  tajuk utama  {\"0\": [true, true], \"1\": [false, false, false]...   \n",
       "4  tajuk utama  {\"0\": [false, true], \"1\": [true, true, true], ...   \n",
       "\n",
       "                                                  id  \\\n",
       "0  1501893029-lula-kamal-dokter-ryan-thamrin-saki...   \n",
       "1  1509072914-dua-smartphone-zenfone-baru-tawarka...   \n",
       "2  1510613677-songsong-visit-2020-bengkulu-perkua...   \n",
       "3  1502706803-icw-ada-kejanggalan-atas-tewasnya-s...   \n",
       "4  1503039338-pembagian-sepeda-usai-upacara-penur...   \n",
       "\n",
       "                                          paragraphs          source  \\\n",
       "0  {\"0\": [\"Jakarta , CNN Indonesia - - Dokter Rya...   cnn indonesia   \n",
       "1  {\"0\": [\"Selfie ialah salah satu tema terpanas ...  dailysocial.id   \n",
       "2  {\"0\": [\"Jakarta , CNN Indonesia - - Dinas Pari...   cnn indonesia   \n",
       "3  {\"0\": [\"Merdeka.com - Indonesia Corruption Wat...         merdeka   \n",
       "4  {\"0\": [\"Merdeka.com - Presiden Joko Widodo ( J...         merdeka   \n",
       "\n",
       "                                          source_url  \\\n",
       "0  https://www.cnnindonesia.com/hiburan/201708041...   \n",
       "1  https://dailysocial.id/post/dua-smartphone-zen...   \n",
       "2  https://www.cnnindonesia.com/gaya-hidup/201711...   \n",
       "3  https://www.merdeka.com/peristiwa/icw-merasa-a...   \n",
       "4  https://www.merdeka.com/peristiwa/usai-upacara...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  {\"0\": \"Dokter Lula Kamal yang merupakan selebr...   \n",
       "1  {\"0\": \"Asus memperkenalkan \\u00a0 ZenFone gene...   \n",
       "2  {\"0\": \"Dinas Pariwisata Provinsi Bengkulu kemb...   \n",
       "3  {\"0\": \"Indonesia Corruption Watch ( ICW ) memi...   \n",
       "4  {\"0\": \"Jokowi memimpin upacara penurunan bende...   \n",
       "\n",
       "                                           news_text  num_of_paragraphs  \\\n",
       "0  Jakarta , CNN Indonesia - - Dokter Ryan Thamri...                  9   \n",
       "1  Selfie ialah salah satu tema terpanas di kalan...                 14   \n",
       "2  Jakarta , CNN Indonesia - - Dinas Pariwisata P...                 21   \n",
       "3  Merdeka.com - Indonesia Corruption Watch ( ICW...                  5   \n",
       "4  Merdeka.com - Presiden Joko Widodo ( Jokowi ) ...                  7   \n",
       "\n",
       "                                        summary_text  num_of_summary  \n",
       "0  Dokter Lula Kamal yang merupakan selebriti sek...               3  \n",
       "1  Asus memperkenalkan   ZenFone generasi keempat...               3  \n",
       "2  Dinas Pariwisata Provinsi Bengkulu kembali men...               2  \n",
       "3  Indonesia Corruption Watch ( ICW ) meminta Kom...               2  \n",
       "4  Jokowi memimpin upacara penurunan bendera . Us...               5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# Path dataset (sesuaikan dengan lokasi dataset Anda di Colab)\n",
    "DATASET_ROOT = './indosum'\n",
    "\n",
    "# Buat folder jika dataset belum ada\n",
    "if not os.path.exists(DATASET_ROOT):\n",
    "    os.makedirs(DATASET_ROOT)\n",
    "\n",
    "# Pastikan file dataset diunggah ke folder ini sebelum menjalankan kode\n",
    "files_id_dir = os.listdir(DATASET_ROOT)\n",
    "train_files = []\n",
    "\n",
    "for filename in files_id_dir:\n",
    "    if 'train' in filename:\n",
    "        train_files.append(filename)\n",
    "        \n",
    "# Fungsi untuk memuat data JSON Lines\n",
    "def load_file_to_json_list(filename):\n",
    "    file = os.path.join(DATASET_ROOT, filename)\n",
    "\n",
    "    data = []\n",
    "    with open(file, 'r') as f:\n",
    "        # Read the entire file content\n",
    "        file_content = f.read()\n",
    "        \n",
    "        # Split the content into individual JSON objects\n",
    "        json_list = file_content.splitlines() \n",
    "        \n",
    "        for json_str in tqdm(json_list, desc=f'Loading data {filename}'):\n",
    "            # Skip empty lines\n",
    "            if json_str.strip(): \n",
    "                try:\n",
    "                    d = json.loads(json_str)\n",
    "                    data.append(d)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    print(f\"Problematic JSON string: {json_str}\")\n",
    "                    # You might want to handle the error, e.g., skip the line or try to fix the JSON\n",
    "                    \n",
    "    return data\n",
    "\n",
    "# Fungsi untuk memproses label menjadi string JSON\n",
    "def label_to_dict_str(label_list):\n",
    "    label_dict = {}  # key = paragraph_id : value = label list \n",
    "    for i, label in enumerate(label_list[:]):\n",
    "        label_dict[i] = label\n",
    "\n",
    "    json_str = json.dumps(label_dict)\n",
    "    num = len(label_dict)\n",
    "    return json_str, num\n",
    "\n",
    "# Fungsi untuk memproses paragraph menjadi string JSON\n",
    "def paragraph_to_dict_str(paragraph_list):\n",
    "    paragraph_dict = {}  # key = paragraph_id : value = paragraph list \n",
    "    for i, paragraph in enumerate(paragraph_list):\n",
    "        new_paragraph = []\n",
    "        for sentence in paragraph:\n",
    "            sentence = ' '.join(sentence)\n",
    "            new_paragraph.append(sentence)\n",
    "        paragraph_dict[i] = new_paragraph\n",
    "\n",
    "    json_str = json.dumps(paragraph_dict)\n",
    "    num = len(paragraph_dict)\n",
    "    return json_str, num\n",
    "    \n",
    "# Fungsi untuk mengubah paragraf menjadi string teks\n",
    "def paragraph_to_text(raw_paragraph_list):\n",
    "    new_paragraph_list = []\n",
    "    for i, paragraph in enumerate(raw_paragraph_list):\n",
    "        paragraph_list = []\n",
    "        for sentence in paragraph:\n",
    "            sentence = ' '.join(sentence)\n",
    "            paragraph_list.append(sentence)\n",
    "\n",
    "        new_paragraph = ' '.join(paragraph_list)\n",
    "        new_paragraph_list.append(new_paragraph)\n",
    "\n",
    "    paragraph_str = ' '.join(new_paragraph_list)\n",
    "    return paragraph_str\n",
    "\n",
    "# Fungsi untuk memproses summary menjadi string JSON\n",
    "def summary_to_dict_str(summary_list):\n",
    "    summary_dict = {}  # key = summary_id : value = summary sentence \n",
    "    for i, summary in enumerate(summary_list):\n",
    "        summary_dict[i] = ' '.join(summary)\n",
    "\n",
    "    json_str = json.dumps(summary_dict)\n",
    "    num = len(summary_dict)\n",
    "    return json_str, num\n",
    "# Fungsi untuk mengubah summary menjadi string teks\n",
    "def summary_to_text(raw_summary_list):\n",
    "    summary_list = []\n",
    "    for i, summary in enumerate(raw_summary_list):\n",
    "        summary_list.append(' '.join(summary))\n",
    "\n",
    "    summary_str = ' '.join(summary_list)\n",
    "    return summary_str\n",
    "\n",
    "# Fungsi untuk mengubah data JSON\n",
    "def alter_json_data(json_list_data, filename=''):\n",
    "    new_json_list = []\n",
    "    for json_data in tqdm(json_list_data, desc=f'Altering json data {filename}'):\n",
    "        json_data = json_data.copy()\n",
    "        json_data['gold_labels'], _ = label_to_dict_str(json_data['gold_labels'])\n",
    "        json_data['news_text'] = paragraph_to_text(json_data['paragraphs'])\n",
    "        json_data['paragraphs'], num_paragraph = paragraph_to_dict_str(json_data['paragraphs'])\n",
    "        json_data['num_of_paragraphs'] = num_paragraph\n",
    "        json_data['summary_text'] = summary_to_text(json_data['summary'])\n",
    "        json_data['summary'], num_summary = summary_to_dict_str(json_data['summary'])\n",
    "        json_data['num_of_summary'] = num_summary\n",
    "\n",
    "        new_json_list.append(json_data)\n",
    "    \n",
    "    return new_json_list\n",
    "\n",
    "# Fungsi untuk membuat dataset dari JSON Lines\n",
    "def create_dataset(jsonl):\n",
    "    header = list(jsonl[0].keys())\n",
    "    dataset_list = []\n",
    "    for json_data in jsonl:\n",
    "        row = []\n",
    "        for h in header:\n",
    "            row.append(json_data[h])\n",
    "        dataset_list.append(row)\n",
    "    \n",
    "    return header, dataset_list\n",
    "\n",
    "# Fungsi untuk membuat dataset dari file JSON Lines\n",
    "def create_dataset_from_files(file_list):\n",
    "    df_header = None\n",
    "    dataset_list = []\n",
    "    for filename in file_list:\n",
    "        json_l = load_file_to_json_list(filename)\n",
    "        new_json_l = alter_json_data(json_l, filename)\n",
    "        header, dataset_part = create_dataset(new_json_l)\n",
    "        \n",
    "        if not df_header: df_header = header\n",
    "        dataset_list.extend(dataset_part)\n",
    "        \n",
    "    df_full = pd.DataFrame().from_records(dataset_list)\n",
    "    df_full = df_full.rename(columns=dict(enumerate(header)))\n",
    "    return df_full\n",
    "\n",
    "# Proses hanya data train\n",
    "df_train = create_dataset_from_files(train_files)\n",
    "\n",
    "# Tampilkan hasil\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Arief M\\.cache\\huggingface\\hub\\models--google--mt5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'max_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Generate summaries using mT5\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df_train[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_text\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead(max_steps)\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39mmax_steps):\n\u001b[1;32m---> 32\u001b[0m     sg \u001b[38;5;241m=\u001b[39m generate_mt5_summary(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_text\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mmax_length\u001b[49m, mt5_tokenizer, mt5_model)\n\u001b[0;32m     33\u001b[0m     summary_generated_mt5\u001b[38;5;241m.\u001b[39mappend([row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], sg])\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_length' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import MT5Tokenizer, MT5ForConditionalGeneration\n",
    "\n",
    "# Load mT5 large tokenizer and model\n",
    "mt5_tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-large\")\n",
    "mt5_model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-large\")\n",
    "\n",
    "# Set device (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "mt5_model = mt5_model.to(device)\n",
    "\n",
    "# Define summary generation function for mT5\n",
    "def generate_mt5_summary(article, max_length, tokenizer, model):\n",
    "    input_ids = tokenizer.encode(article, return_tensors='pt', truncation=True)\n",
    "    input_ids = input_ids.to(device)\n",
    "    summary_ids = model.generate(input_ids,\n",
    "                                 max_length=512,\n",
    "                                 num_beams=4,\n",
    "                                 repetition_penalty=2.5,\n",
    "                                 length_penalty=1.0,\n",
    "                                 early_stopping=True,\n",
    "                                 no_repeat_ngram_size=8)\n",
    "    summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary_text\n",
    "\n",
    "# Batasi jumlah data yang akan diproses\n",
    "max_steps = 10  # Ubah sesuai kebutuhan Anda\n",
    "summary_generated_mt5 = []\n",
    "\n",
    "# Generate summaries using mT5\n",
    "for i, row in tqdm(df_train[['id', 'news_text']].head(max_steps).iterrows(), total=max_steps):\n",
    "    sg = generate_mt5_summary(row['news_text'], max_length, mt5_tokenizer, mt5_model)\n",
    "    summary_generated_mt5.append([row['id'], sg])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_summary_generated_mt5 = pd.DataFrame(summary_generated_mt5, columns=['id', 'summary_generated_mt5'])\n",
    "\n",
    "# Merge with original dataset\n",
    "df_train_result_mt5 = df_train.head(max_steps).merge(df_summary_generated_mt5, on='id')\n",
    "df_train_result_mt5.head()\n",
    "\n",
    "# Evaluate using ROUGE\n",
    "rouge = evaluate.load('rouge')\n",
    "results_mt5 = rouge.compute(\n",
    "    references=df_train_result_mt5['summary_text'].values,\n",
    "    predictions=df_train_result_mt5['summary_generated_mt5'].values)\n",
    "print(results_mt5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
