{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: sastrawi in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: evaluate in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (4.67.0)\n",
      "Requirement already satisfied: torch in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: gensim in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: dill in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from evaluate) (0.26.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from datasets>=2.0.0->evaluate) (18.0.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: wrapt in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (C:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (C:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (C:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas scikit-learn numpy sastrawi nltk evaluate tqdm torch nltk gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import T5Tokenizer, T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Arief\n",
      "[nltk_data]     M\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path dataset (sesuaikan dengan lokasi dataset Anda di Colab)\n",
    "DATASET_ROOT = './indosum'\n",
    "\n",
    "# Buat folder jika dataset belum ada\n",
    "if not os.path.exists(DATASET_ROOT):\n",
    "    os.makedirs(DATASET_ROOT)\n",
    "\n",
    "# Pastikan file dataset diunggah ke folder ini sebelum menjalankan kode\n",
    "files_id_dir = os.listdir(DATASET_ROOT)\n",
    "train_files = []\n",
    "\n",
    "for filename in files_id_dir:\n",
    "    if 'train' in filename:\n",
    "        train_files.append(filename)\n",
    "        \n",
    "# Fungsi untuk memuat data JSON Lines\n",
    "def load_file_to_json_list(filename):\n",
    "    file = os.path.join(DATASET_ROOT, filename)\n",
    "\n",
    "    data = []\n",
    "    with open(file, 'r') as f:\n",
    "        # Read the entire file content\n",
    "        file_content = f.read()\n",
    "        \n",
    "        # Split the content into individual JSON objects\n",
    "        json_list = file_content.splitlines() \n",
    "        \n",
    "        for json_str in tqdm(json_list, desc=f'Loading data {filename}'):\n",
    "            # Skip empty lines\n",
    "            if json_str.strip(): \n",
    "                try:\n",
    "                    d = json.loads(json_str)\n",
    "                    data.append(d)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    print(f\"Problematic JSON string: {json_str}\")\n",
    "                    # You might want to handle the error, e.g., skip the line or try to fix the JSON\n",
    "                    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memproses label menjadi string JSON\n",
    "def label_to_dict_str(label_list):\n",
    "    label_dict = {}  # key = paragraph_id : value = label list \n",
    "    for i, label in enumerate(label_list[:]):\n",
    "        label_dict[i] = label\n",
    "\n",
    "    json_str = json.dumps(label_dict)\n",
    "    num = len(label_dict)\n",
    "    return json_str, num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memproses paragraph menjadi string JSON\n",
    "def paragraph_to_dict_str(paragraph_list):\n",
    "    paragraph_dict = {}  # key = paragraph_id : value = paragraph list \n",
    "    for i, paragraph in enumerate(paragraph_list):\n",
    "        new_paragraph = []\n",
    "        for sentence in paragraph:\n",
    "            sentence = ' '.join(sentence)\n",
    "            new_paragraph.append(sentence)\n",
    "        paragraph_dict[i] = new_paragraph\n",
    "\n",
    "    json_str = json.dumps(paragraph_dict)\n",
    "    num = len(paragraph_dict)\n",
    "    return json_str, num\n",
    "    \n",
    "# Fungsi untuk mengubah paragraf menjadi string teks\n",
    "def paragraph_to_text(raw_paragraph_list):\n",
    "    new_paragraph_list = []\n",
    "    for i, paragraph in enumerate(raw_paragraph_list):\n",
    "        paragraph_list = []\n",
    "        for sentence in paragraph:\n",
    "            sentence = ' '.join(sentence)\n",
    "            paragraph_list.append(sentence)\n",
    "\n",
    "        new_paragraph = ' '.join(paragraph_list)\n",
    "        new_paragraph_list.append(new_paragraph)\n",
    "\n",
    "    paragraph_str = ' '.join(new_paragraph_list)\n",
    "    return paragraph_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memproses summary menjadi string JSON\n",
    "def summary_to_dict_str(summary_list):\n",
    "    summary_dict = {}  # key = summary_id : value = summary sentence \n",
    "    for i, summary in enumerate(summary_list):\n",
    "        summary_dict[i] = ' '.join(summary)\n",
    "\n",
    "    json_str = json.dumps(summary_dict)\n",
    "    num = len(summary_dict)\n",
    "    return json_str, num\n",
    "# Fungsi untuk mengubah summary menjadi string teks\n",
    "def summary_to_text(raw_summary_list):\n",
    "    summary_list = []\n",
    "    for i, summary in enumerate(raw_summary_list):\n",
    "        summary_list.append(' '.join(summary))\n",
    "\n",
    "    summary_str = ' '.join(summary_list)\n",
    "    return summary_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fungsi untuk mengubah data JSON\n",
    "def alter_json_data(json_list_data, filename=''):\n",
    "    new_json_list = []\n",
    "    for json_data in tqdm(json_list_data, desc=f'Altering json data {filename}'):\n",
    "        json_data = json_data.copy()\n",
    "        json_data['gold_labels'], _ = label_to_dict_str(json_data['gold_labels'])\n",
    "        json_data['news_text'] = paragraph_to_text(json_data['paragraphs'])\n",
    "        json_data['paragraphs'], num_paragraph = paragraph_to_dict_str(json_data['paragraphs'])\n",
    "        json_data['num_of_paragraphs'] = num_paragraph\n",
    "        json_data['summary_text'] = summary_to_text(json_data['summary'])\n",
    "        json_data['summary'], num_summary = summary_to_dict_str(json_data['summary'])\n",
    "        json_data['num_of_summary'] = num_summary\n",
    "\n",
    "        new_json_list.append(json_data)\n",
    "    \n",
    "    return new_json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membuat dataset dari JSON Lines\n",
    "def create_dataset(jsonl):\n",
    "    header = list(jsonl[0].keys())\n",
    "    dataset_list = []\n",
    "    for json_data in jsonl:\n",
    "        row = []\n",
    "        for h in header:\n",
    "            row.append(json_data[h])\n",
    "        dataset_list.append(row)\n",
    "    \n",
    "    return header, dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data train.01.jsonl: 100%|██████████| 14262/14262 [00:01<00:00, 7805.04it/s] \n",
      "Altering json data train.01.jsonl: 100%|██████████| 14262/14262 [00:00<00:00, 22208.83it/s]\n",
      "Loading data train.02.jsonl: 100%|██████████| 14263/14263 [00:01<00:00, 7860.62it/s]\n",
      "Altering json data train.02.jsonl: 100%|██████████| 14263/14263 [00:00<00:00, 23872.36it/s]\n",
      "Loading data train.03.jsonl: 100%|██████████| 14290/14290 [00:01<00:00, 9653.09it/s]\n",
      "Altering json data train.03.jsonl: 100%|██████████| 14290/14290 [00:00<00:00, 24526.75it/s]\n",
      "Loading data train.04.jsonl: 100%|██████████| 14272/14272 [00:01<00:00, 9097.43it/s]\n",
      "Altering json data train.04.jsonl: 100%|██████████| 14272/14272 [00:00<00:00, 23867.61it/s]\n",
      "Loading data train.05.jsonl: 100%|██████████| 14266/14266 [00:01<00:00, 8652.25it/s]\n",
      "Altering json data train.05.jsonl: 100%|██████████| 14266/14266 [00:00<00:00, 23261.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>gold_labels</th>\n",
       "      <th>id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>source</th>\n",
       "      <th>source_url</th>\n",
       "      <th>summary</th>\n",
       "      <th>news_text</th>\n",
       "      <th>num_of_paragraphs</th>\n",
       "      <th>summary_text</th>\n",
       "      <th>num_of_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [false, true], \"1\": [true, true], \"2\": [...</td>\n",
       "      <td>1501893029-lula-kamal-dokter-ryan-thamrin-saki...</td>\n",
       "      <td>{\"0\": [\"Jakarta , CNN Indonesia - - Dokter Rya...</td>\n",
       "      <td>cnn indonesia</td>\n",
       "      <td>https://www.cnnindonesia.com/hiburan/201708041...</td>\n",
       "      <td>{\"0\": \"Dokter Lula Kamal yang merupakan selebr...</td>\n",
       "      <td>Jakarta , CNN Indonesia - - Dokter Ryan Thamri...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dokter Lula Kamal yang merupakan selebriti sek...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teknologi</td>\n",
       "      <td>{\"0\": [false, false, false, false], \"1\": [fals...</td>\n",
       "      <td>1509072914-dua-smartphone-zenfone-baru-tawarka...</td>\n",
       "      <td>{\"0\": [\"Selfie ialah salah satu tema terpanas ...</td>\n",
       "      <td>dailysocial.id</td>\n",
       "      <td>https://dailysocial.id/post/dua-smartphone-zen...</td>\n",
       "      <td>{\"0\": \"Asus memperkenalkan \\u00a0 ZenFone gene...</td>\n",
       "      <td>Selfie ialah salah satu tema terpanas di kalan...</td>\n",
       "      <td>14</td>\n",
       "      <td>Asus memperkenalkan   ZenFone generasi keempat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hiburan</td>\n",
       "      <td>{\"0\": [true], \"1\": [true], \"2\": [false, false]...</td>\n",
       "      <td>1510613677-songsong-visit-2020-bengkulu-perkua...</td>\n",
       "      <td>{\"0\": [\"Jakarta , CNN Indonesia - - Dinas Pari...</td>\n",
       "      <td>cnn indonesia</td>\n",
       "      <td>https://www.cnnindonesia.com/gaya-hidup/201711...</td>\n",
       "      <td>{\"0\": \"Dinas Pariwisata Provinsi Bengkulu kemb...</td>\n",
       "      <td>Jakarta , CNN Indonesia - - Dinas Pariwisata P...</td>\n",
       "      <td>21</td>\n",
       "      <td>Dinas Pariwisata Provinsi Bengkulu kembali men...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [true, true], \"1\": [false, false, false]...</td>\n",
       "      <td>1502706803-icw-ada-kejanggalan-atas-tewasnya-s...</td>\n",
       "      <td>{\"0\": [\"Merdeka.com - Indonesia Corruption Wat...</td>\n",
       "      <td>merdeka</td>\n",
       "      <td>https://www.merdeka.com/peristiwa/icw-merasa-a...</td>\n",
       "      <td>{\"0\": \"Indonesia Corruption Watch ( ICW ) memi...</td>\n",
       "      <td>Merdeka.com - Indonesia Corruption Watch ( ICW...</td>\n",
       "      <td>5</td>\n",
       "      <td>Indonesia Corruption Watch ( ICW ) meminta Kom...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [false, true], \"1\": [true, true, true], ...</td>\n",
       "      <td>1503039338-pembagian-sepeda-usai-upacara-penur...</td>\n",
       "      <td>{\"0\": [\"Merdeka.com - Presiden Joko Widodo ( J...</td>\n",
       "      <td>merdeka</td>\n",
       "      <td>https://www.merdeka.com/peristiwa/usai-upacara...</td>\n",
       "      <td>{\"0\": \"Jokowi memimpin upacara penurunan bende...</td>\n",
       "      <td>Merdeka.com - Presiden Joko Widodo ( Jokowi ) ...</td>\n",
       "      <td>7</td>\n",
       "      <td>Jokowi memimpin upacara penurunan bendera . Us...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                        gold_labels  \\\n",
       "0  tajuk utama  {\"0\": [false, true], \"1\": [true, true], \"2\": [...   \n",
       "1    teknologi  {\"0\": [false, false, false, false], \"1\": [fals...   \n",
       "2      hiburan  {\"0\": [true], \"1\": [true], \"2\": [false, false]...   \n",
       "3  tajuk utama  {\"0\": [true, true], \"1\": [false, false, false]...   \n",
       "4  tajuk utama  {\"0\": [false, true], \"1\": [true, true, true], ...   \n",
       "\n",
       "                                                  id  \\\n",
       "0  1501893029-lula-kamal-dokter-ryan-thamrin-saki...   \n",
       "1  1509072914-dua-smartphone-zenfone-baru-tawarka...   \n",
       "2  1510613677-songsong-visit-2020-bengkulu-perkua...   \n",
       "3  1502706803-icw-ada-kejanggalan-atas-tewasnya-s...   \n",
       "4  1503039338-pembagian-sepeda-usai-upacara-penur...   \n",
       "\n",
       "                                          paragraphs          source  \\\n",
       "0  {\"0\": [\"Jakarta , CNN Indonesia - - Dokter Rya...   cnn indonesia   \n",
       "1  {\"0\": [\"Selfie ialah salah satu tema terpanas ...  dailysocial.id   \n",
       "2  {\"0\": [\"Jakarta , CNN Indonesia - - Dinas Pari...   cnn indonesia   \n",
       "3  {\"0\": [\"Merdeka.com - Indonesia Corruption Wat...         merdeka   \n",
       "4  {\"0\": [\"Merdeka.com - Presiden Joko Widodo ( J...         merdeka   \n",
       "\n",
       "                                          source_url  \\\n",
       "0  https://www.cnnindonesia.com/hiburan/201708041...   \n",
       "1  https://dailysocial.id/post/dua-smartphone-zen...   \n",
       "2  https://www.cnnindonesia.com/gaya-hidup/201711...   \n",
       "3  https://www.merdeka.com/peristiwa/icw-merasa-a...   \n",
       "4  https://www.merdeka.com/peristiwa/usai-upacara...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  {\"0\": \"Dokter Lula Kamal yang merupakan selebr...   \n",
       "1  {\"0\": \"Asus memperkenalkan \\u00a0 ZenFone gene...   \n",
       "2  {\"0\": \"Dinas Pariwisata Provinsi Bengkulu kemb...   \n",
       "3  {\"0\": \"Indonesia Corruption Watch ( ICW ) memi...   \n",
       "4  {\"0\": \"Jokowi memimpin upacara penurunan bende...   \n",
       "\n",
       "                                           news_text  num_of_paragraphs  \\\n",
       "0  Jakarta , CNN Indonesia - - Dokter Ryan Thamri...                  9   \n",
       "1  Selfie ialah salah satu tema terpanas di kalan...                 14   \n",
       "2  Jakarta , CNN Indonesia - - Dinas Pariwisata P...                 21   \n",
       "3  Merdeka.com - Indonesia Corruption Watch ( ICW...                  5   \n",
       "4  Merdeka.com - Presiden Joko Widodo ( Jokowi ) ...                  7   \n",
       "\n",
       "                                        summary_text  num_of_summary  \n",
       "0  Dokter Lula Kamal yang merupakan selebriti sek...               3  \n",
       "1  Asus memperkenalkan   ZenFone generasi keempat...               3  \n",
       "2  Dinas Pariwisata Provinsi Bengkulu kembali men...               2  \n",
       "3  Indonesia Corruption Watch ( ICW ) meminta Kom...               2  \n",
       "4  Jokowi memimpin upacara penurunan bendera . Us...               5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fungsi untuk membuat dataset dari file JSON Lines\n",
    "def create_dataset_from_files(file_list):\n",
    "    df_header = None\n",
    "    dataset_list = []\n",
    "    for filename in file_list:\n",
    "        json_l = load_file_to_json_list(filename)\n",
    "        new_json_l = alter_json_data(json_l, filename)\n",
    "        header, dataset_part = create_dataset(new_json_l)\n",
    "        \n",
    "        if not df_header: df_header = header\n",
    "        dataset_list.extend(dataset_part)\n",
    "        \n",
    "    df_full = pd.DataFrame().from_records(dataset_list)\n",
    "    df_full = df_full.rename(columns=dict(enumerate(header)))\n",
    "    return df_full\n",
    "\n",
    "# Proses hanya data train\n",
    "df_train = create_dataset_from_files(train_files)\n",
    "\n",
    "# Tampilkan hasil\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Load T5 tokenizer and model\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"panggi/t5-base-indonesian-summarization-cased\")\n",
    "t5_model = T5Model.from_pretrained(\"panggi/t5-base-indonesian-summarization-cased\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text without NLTK and retain stop words\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Tokenize sentences using simple splitting and retain stop words.\"\"\"\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').strip()  # Remove newlines and strip extra spaces\n",
    "    sentences = text.split('. ')\n",
    "    sentences = [sentence.strip() for sentence in sentences if len(sentence.strip()) > 0]  # Include all valid sentences\n",
    "    return sentences\n",
    "\n",
    "# Build similarity matrix using TF-IDF\n",
    "def build_similarity_matrix(sentences):\n",
    "    \"\"\"Build cosine similarity matrix for sentences using TF-IDF without removing stop words.\"\"\"\n",
    "    vectorizer = TfidfVectorizer()  # Do not use stop_words='english'\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    return similarity_matrix\n",
    "\n",
    "def lexrank(sentences, similarity_matrix, threshold=0.05):\n",
    "    \"\"\"Run LexRank algorithm to score sentences.\"\"\"\n",
    "    n = len(sentences)\n",
    "    scores = np.ones(n) / n\n",
    "    adjacency_matrix = (similarity_matrix > threshold).astype(float)\n",
    "    row_sums = adjacency_matrix.sum(axis=1)\n",
    "    row_sums[row_sums == 0] = 1  # Avoid division by zero\n",
    "    adjacency_matrix = adjacency_matrix / row_sums[:, np.newaxis]\n",
    "    for _ in range(150):  # Increase iterations for convergence\n",
    "        scores = 0.9 * adjacency_matrix.T.dot(scores) + 0.1 / n\n",
    "    return scores\n",
    "\n",
    "def summarize_text(text, max_words=50):\n",
    "    \"\"\"Summarize text using LexRank.\"\"\"\n",
    "    sentences = preprocess_text(text)\n",
    "    if len(sentences) == 0:\n",
    "        return \"\"  # Return empty summary if no valid sentences\n",
    "    similarity_matrix = build_similarity_matrix(sentences)\n",
    "    scores = lexrank(sentences, similarity_matrix)\n",
    "    ranked_sentences = [sentences[i] for i in np.argsort(scores)[::-1]]\n",
    "    summary = []\n",
    "    word_count = 0\n",
    "    for sentence in ranked_sentences:\n",
    "        word_count += len(sentence.split())\n",
    "        if word_count > max_words:\n",
    "            break\n",
    "        summary.append(sentence)\n",
    "    return \" \".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "max_steps = 1000 # Limit number of rows to process\n",
    "summary_generated = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 640.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(df_train[['id', 'news_text']].head(max_steps).iterrows(), total=max_steps):\n",
    "    sg = summarize_text(row['news_text'], max_words=75)\n",
    "    summary_generated.append([row['id'], sg])\n",
    "\n",
    "# Konversi hasil menjadi DataFrame\n",
    "df_summary_generated = pd.DataFrame(summary_generated, columns=['id', 'summary_generated'])\n",
    "\n",
    "# Gabungkan dengan dataset asli\n",
    "df_train_result = df_train.head(max_steps).merge(df_summary_generated, on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.41267042289142525, 'rouge2': 0.2668166875418545, 'rougeL': 0.3096750581462644, 'rougeLsum': 0.3100984763102359}\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi menggunakan ROUGE\n",
    "rouge = evaluate.load('rouge')\n",
    "results = rouge.compute(\n",
    "    references=df_train_result['summary_text'].values,\n",
    "    predictions=df_train_result['summary_generated'].values\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>gold_labels</th>\n",
       "      <th>id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>source</th>\n",
       "      <th>source_url</th>\n",
       "      <th>summary</th>\n",
       "      <th>news_text</th>\n",
       "      <th>num_of_paragraphs</th>\n",
       "      <th>summary_text</th>\n",
       "      <th>num_of_summary</th>\n",
       "      <th>summary_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [false, true], \"1\": [true, true], \"2\": [...</td>\n",
       "      <td>1501893029-lula-kamal-dokter-ryan-thamrin-saki...</td>\n",
       "      <td>{\"0\": [\"Jakarta , CNN Indonesia - - Dokter Rya...</td>\n",
       "      <td>cnn indonesia</td>\n",
       "      <td>https://www.cnnindonesia.com/hiburan/201708041...</td>\n",
       "      <td>{\"0\": \"Dokter Lula Kamal yang merupakan selebr...</td>\n",
       "      <td>Jakarta , CNN Indonesia - - Dokter Ryan Thamri...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dokter Lula Kamal yang merupakan selebriti sek...</td>\n",
       "      <td>3</td>\n",
       "      <td>Dia juga tak tahu penyakit apa yang diderita R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teknologi</td>\n",
       "      <td>{\"0\": [false, false, false, false], \"1\": [fals...</td>\n",
       "      <td>1509072914-dua-smartphone-zenfone-baru-tawarka...</td>\n",
       "      <td>{\"0\": [\"Selfie ialah salah satu tema terpanas ...</td>\n",
       "      <td>dailysocial.id</td>\n",
       "      <td>https://dailysocial.id/post/dua-smartphone-zen...</td>\n",
       "      <td>{\"0\": \"Asus memperkenalkan \\u00a0 ZenFone gene...</td>\n",
       "      <td>Selfie ialah salah satu tema terpanas di kalan...</td>\n",
       "      <td>14</td>\n",
       "      <td>Asus memperkenalkan   ZenFone generasi keempat...</td>\n",
       "      <td>3</td>\n",
       "      <td>Mereka adalah Asus ZenFone 4 Selfie Pro ZD552K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hiburan</td>\n",
       "      <td>{\"0\": [true], \"1\": [true], \"2\": [false, false]...</td>\n",
       "      <td>1510613677-songsong-visit-2020-bengkulu-perkua...</td>\n",
       "      <td>{\"0\": [\"Jakarta , CNN Indonesia - - Dinas Pari...</td>\n",
       "      <td>cnn indonesia</td>\n",
       "      <td>https://www.cnnindonesia.com/gaya-hidup/201711...</td>\n",
       "      <td>{\"0\": \"Dinas Pariwisata Provinsi Bengkulu kemb...</td>\n",
       "      <td>Jakarta , CNN Indonesia - - Dinas Pariwisata P...</td>\n",
       "      <td>21</td>\n",
       "      <td>Dinas Pariwisata Provinsi Bengkulu kembali men...</td>\n",
       "      <td>2</td>\n",
       "      <td>Deputi Pengembangan Pemasaran Pariwisata Nusan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [true, true], \"1\": [false, false, false]...</td>\n",
       "      <td>1502706803-icw-ada-kejanggalan-atas-tewasnya-s...</td>\n",
       "      <td>{\"0\": [\"Merdeka.com - Indonesia Corruption Wat...</td>\n",
       "      <td>merdeka</td>\n",
       "      <td>https://www.merdeka.com/peristiwa/icw-merasa-a...</td>\n",
       "      <td>{\"0\": \"Indonesia Corruption Watch ( ICW ) memi...</td>\n",
       "      <td>Merdeka.com - Indonesia Corruption Watch ( ICW...</td>\n",
       "      <td>5</td>\n",
       "      <td>Indonesia Corruption Watch ( ICW ) meminta Kom...</td>\n",
       "      <td>2</td>\n",
       "      <td>Kenapa momentum meninggalnya , saat kasus e - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [false, true], \"1\": [true, true, true], ...</td>\n",
       "      <td>1503039338-pembagian-sepeda-usai-upacara-penur...</td>\n",
       "      <td>{\"0\": [\"Merdeka.com - Presiden Joko Widodo ( J...</td>\n",
       "      <td>merdeka</td>\n",
       "      <td>https://www.merdeka.com/peristiwa/usai-upacara...</td>\n",
       "      <td>{\"0\": \"Jokowi memimpin upacara penurunan bende...</td>\n",
       "      <td>Merdeka.com - Presiden Joko Widodo ( Jokowi ) ...</td>\n",
       "      <td>7</td>\n",
       "      <td>Jokowi memimpin upacara penurunan bendera . Us...</td>\n",
       "      <td>5</td>\n",
       "      <td>Usai prosesi penurunan bendera dilakukan , Jok...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                        gold_labels  \\\n",
       "0  tajuk utama  {\"0\": [false, true], \"1\": [true, true], \"2\": [...   \n",
       "1    teknologi  {\"0\": [false, false, false, false], \"1\": [fals...   \n",
       "2      hiburan  {\"0\": [true], \"1\": [true], \"2\": [false, false]...   \n",
       "3  tajuk utama  {\"0\": [true, true], \"1\": [false, false, false]...   \n",
       "4  tajuk utama  {\"0\": [false, true], \"1\": [true, true, true], ...   \n",
       "\n",
       "                                                  id  \\\n",
       "0  1501893029-lula-kamal-dokter-ryan-thamrin-saki...   \n",
       "1  1509072914-dua-smartphone-zenfone-baru-tawarka...   \n",
       "2  1510613677-songsong-visit-2020-bengkulu-perkua...   \n",
       "3  1502706803-icw-ada-kejanggalan-atas-tewasnya-s...   \n",
       "4  1503039338-pembagian-sepeda-usai-upacara-penur...   \n",
       "\n",
       "                                          paragraphs          source  \\\n",
       "0  {\"0\": [\"Jakarta , CNN Indonesia - - Dokter Rya...   cnn indonesia   \n",
       "1  {\"0\": [\"Selfie ialah salah satu tema terpanas ...  dailysocial.id   \n",
       "2  {\"0\": [\"Jakarta , CNN Indonesia - - Dinas Pari...   cnn indonesia   \n",
       "3  {\"0\": [\"Merdeka.com - Indonesia Corruption Wat...         merdeka   \n",
       "4  {\"0\": [\"Merdeka.com - Presiden Joko Widodo ( J...         merdeka   \n",
       "\n",
       "                                          source_url  \\\n",
       "0  https://www.cnnindonesia.com/hiburan/201708041...   \n",
       "1  https://dailysocial.id/post/dua-smartphone-zen...   \n",
       "2  https://www.cnnindonesia.com/gaya-hidup/201711...   \n",
       "3  https://www.merdeka.com/peristiwa/icw-merasa-a...   \n",
       "4  https://www.merdeka.com/peristiwa/usai-upacara...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  {\"0\": \"Dokter Lula Kamal yang merupakan selebr...   \n",
       "1  {\"0\": \"Asus memperkenalkan \\u00a0 ZenFone gene...   \n",
       "2  {\"0\": \"Dinas Pariwisata Provinsi Bengkulu kemb...   \n",
       "3  {\"0\": \"Indonesia Corruption Watch ( ICW ) memi...   \n",
       "4  {\"0\": \"Jokowi memimpin upacara penurunan bende...   \n",
       "\n",
       "                                           news_text  num_of_paragraphs  \\\n",
       "0  Jakarta , CNN Indonesia - - Dokter Ryan Thamri...                  9   \n",
       "1  Selfie ialah salah satu tema terpanas di kalan...                 14   \n",
       "2  Jakarta , CNN Indonesia - - Dinas Pariwisata P...                 21   \n",
       "3  Merdeka.com - Indonesia Corruption Watch ( ICW...                  5   \n",
       "4  Merdeka.com - Presiden Joko Widodo ( Jokowi ) ...                  7   \n",
       "\n",
       "                                        summary_text  num_of_summary  \\\n",
       "0  Dokter Lula Kamal yang merupakan selebriti sek...               3   \n",
       "1  Asus memperkenalkan   ZenFone generasi keempat...               3   \n",
       "2  Dinas Pariwisata Provinsi Bengkulu kembali men...               2   \n",
       "3  Indonesia Corruption Watch ( ICW ) meminta Kom...               2   \n",
       "4  Jokowi memimpin upacara penurunan bendera . Us...               5   \n",
       "\n",
       "                                   summary_generated  \n",
       "0  Dia juga tak tahu penyakit apa yang diderita R...  \n",
       "1  Mereka adalah Asus ZenFone 4 Selfie Pro ZD552K...  \n",
       "2  Deputi Pengembangan Pemasaran Pariwisata Nusan...  \n",
       "3  Kenapa momentum meninggalnya , saat kasus e - ...  \n",
       "4  Usai prosesi penurunan bendera dilakukan , Jok...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan sampel hasil\n",
    "df_train_result.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
