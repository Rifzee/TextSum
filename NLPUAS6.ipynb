{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data train.01.jsonl: 100%|██████████| 14262/14262 [00:01<00:00, 8763.24it/s]\n",
      "Altering json data train.01.jsonl: 100%|██████████| 14262/14262 [00:00<00:00, 24804.02it/s]\n",
      "Loading data train.02.jsonl: 100%|██████████| 14263/14263 [00:01<00:00, 9224.46it/s]\n",
      "Altering json data train.02.jsonl: 100%|██████████| 14263/14263 [00:00<00:00, 24467.11it/s]\n",
      "Loading data train.03.jsonl: 100%|██████████| 14290/14290 [00:01<00:00, 9384.29it/s] \n",
      "Altering json data train.03.jsonl: 100%|██████████| 14290/14290 [00:00<00:00, 24222.53it/s]\n",
      "Loading data train.04.jsonl: 100%|██████████| 14272/14272 [00:01<00:00, 9010.06it/s] \n",
      "Altering json data train.04.jsonl: 100%|██████████| 14272/14272 [00:00<00:00, 24827.76it/s]\n",
      "Loading data train.05.jsonl: 100%|██████████| 14266/14266 [00:01<00:00, 8442.11it/s]\n",
      "Altering json data train.05.jsonl: 100%|██████████| 14266/14266 [00:00<00:00, 24156.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>gold_labels</th>\n",
       "      <th>id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>source</th>\n",
       "      <th>source_url</th>\n",
       "      <th>summary</th>\n",
       "      <th>news_text</th>\n",
       "      <th>num_of_paragraphs</th>\n",
       "      <th>summary_text</th>\n",
       "      <th>num_of_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [false, true], \"1\": [true, true], \"2\": [...</td>\n",
       "      <td>1501893029-lula-kamal-dokter-ryan-thamrin-saki...</td>\n",
       "      <td>{\"0\": [\"Jakarta , CNN Indonesia - - Dokter Rya...</td>\n",
       "      <td>cnn indonesia</td>\n",
       "      <td>https://www.cnnindonesia.com/hiburan/201708041...</td>\n",
       "      <td>{\"0\": \"Dokter Lula Kamal yang merupakan selebr...</td>\n",
       "      <td>Jakarta , CNN Indonesia - - Dokter Ryan Thamri...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dokter Lula Kamal yang merupakan selebriti sek...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teknologi</td>\n",
       "      <td>{\"0\": [false, false, false, false], \"1\": [fals...</td>\n",
       "      <td>1509072914-dua-smartphone-zenfone-baru-tawarka...</td>\n",
       "      <td>{\"0\": [\"Selfie ialah salah satu tema terpanas ...</td>\n",
       "      <td>dailysocial.id</td>\n",
       "      <td>https://dailysocial.id/post/dua-smartphone-zen...</td>\n",
       "      <td>{\"0\": \"Asus memperkenalkan \\u00a0 ZenFone gene...</td>\n",
       "      <td>Selfie ialah salah satu tema terpanas di kalan...</td>\n",
       "      <td>14</td>\n",
       "      <td>Asus memperkenalkan   ZenFone generasi keempat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hiburan</td>\n",
       "      <td>{\"0\": [true], \"1\": [true], \"2\": [false, false]...</td>\n",
       "      <td>1510613677-songsong-visit-2020-bengkulu-perkua...</td>\n",
       "      <td>{\"0\": [\"Jakarta , CNN Indonesia - - Dinas Pari...</td>\n",
       "      <td>cnn indonesia</td>\n",
       "      <td>https://www.cnnindonesia.com/gaya-hidup/201711...</td>\n",
       "      <td>{\"0\": \"Dinas Pariwisata Provinsi Bengkulu kemb...</td>\n",
       "      <td>Jakarta , CNN Indonesia - - Dinas Pariwisata P...</td>\n",
       "      <td>21</td>\n",
       "      <td>Dinas Pariwisata Provinsi Bengkulu kembali men...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [true, true], \"1\": [false, false, false]...</td>\n",
       "      <td>1502706803-icw-ada-kejanggalan-atas-tewasnya-s...</td>\n",
       "      <td>{\"0\": [\"Merdeka.com - Indonesia Corruption Wat...</td>\n",
       "      <td>merdeka</td>\n",
       "      <td>https://www.merdeka.com/peristiwa/icw-merasa-a...</td>\n",
       "      <td>{\"0\": \"Indonesia Corruption Watch ( ICW ) memi...</td>\n",
       "      <td>Merdeka.com - Indonesia Corruption Watch ( ICW...</td>\n",
       "      <td>5</td>\n",
       "      <td>Indonesia Corruption Watch ( ICW ) meminta Kom...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tajuk utama</td>\n",
       "      <td>{\"0\": [false, true], \"1\": [true, true, true], ...</td>\n",
       "      <td>1503039338-pembagian-sepeda-usai-upacara-penur...</td>\n",
       "      <td>{\"0\": [\"Merdeka.com - Presiden Joko Widodo ( J...</td>\n",
       "      <td>merdeka</td>\n",
       "      <td>https://www.merdeka.com/peristiwa/usai-upacara...</td>\n",
       "      <td>{\"0\": \"Jokowi memimpin upacara penurunan bende...</td>\n",
       "      <td>Merdeka.com - Presiden Joko Widodo ( Jokowi ) ...</td>\n",
       "      <td>7</td>\n",
       "      <td>Jokowi memimpin upacara penurunan bendera . Us...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                        gold_labels  \\\n",
       "0  tajuk utama  {\"0\": [false, true], \"1\": [true, true], \"2\": [...   \n",
       "1    teknologi  {\"0\": [false, false, false, false], \"1\": [fals...   \n",
       "2      hiburan  {\"0\": [true], \"1\": [true], \"2\": [false, false]...   \n",
       "3  tajuk utama  {\"0\": [true, true], \"1\": [false, false, false]...   \n",
       "4  tajuk utama  {\"0\": [false, true], \"1\": [true, true, true], ...   \n",
       "\n",
       "                                                  id  \\\n",
       "0  1501893029-lula-kamal-dokter-ryan-thamrin-saki...   \n",
       "1  1509072914-dua-smartphone-zenfone-baru-tawarka...   \n",
       "2  1510613677-songsong-visit-2020-bengkulu-perkua...   \n",
       "3  1502706803-icw-ada-kejanggalan-atas-tewasnya-s...   \n",
       "4  1503039338-pembagian-sepeda-usai-upacara-penur...   \n",
       "\n",
       "                                          paragraphs          source  \\\n",
       "0  {\"0\": [\"Jakarta , CNN Indonesia - - Dokter Rya...   cnn indonesia   \n",
       "1  {\"0\": [\"Selfie ialah salah satu tema terpanas ...  dailysocial.id   \n",
       "2  {\"0\": [\"Jakarta , CNN Indonesia - - Dinas Pari...   cnn indonesia   \n",
       "3  {\"0\": [\"Merdeka.com - Indonesia Corruption Wat...         merdeka   \n",
       "4  {\"0\": [\"Merdeka.com - Presiden Joko Widodo ( J...         merdeka   \n",
       "\n",
       "                                          source_url  \\\n",
       "0  https://www.cnnindonesia.com/hiburan/201708041...   \n",
       "1  https://dailysocial.id/post/dua-smartphone-zen...   \n",
       "2  https://www.cnnindonesia.com/gaya-hidup/201711...   \n",
       "3  https://www.merdeka.com/peristiwa/icw-merasa-a...   \n",
       "4  https://www.merdeka.com/peristiwa/usai-upacara...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  {\"0\": \"Dokter Lula Kamal yang merupakan selebr...   \n",
       "1  {\"0\": \"Asus memperkenalkan \\u00a0 ZenFone gene...   \n",
       "2  {\"0\": \"Dinas Pariwisata Provinsi Bengkulu kemb...   \n",
       "3  {\"0\": \"Indonesia Corruption Watch ( ICW ) memi...   \n",
       "4  {\"0\": \"Jokowi memimpin upacara penurunan bende...   \n",
       "\n",
       "                                           news_text  num_of_paragraphs  \\\n",
       "0  Jakarta , CNN Indonesia - - Dokter Ryan Thamri...                  9   \n",
       "1  Selfie ialah salah satu tema terpanas di kalan...                 14   \n",
       "2  Jakarta , CNN Indonesia - - Dinas Pariwisata P...                 21   \n",
       "3  Merdeka.com - Indonesia Corruption Watch ( ICW...                  5   \n",
       "4  Merdeka.com - Presiden Joko Widodo ( Jokowi ) ...                  7   \n",
       "\n",
       "                                        summary_text  num_of_summary  \n",
       "0  Dokter Lula Kamal yang merupakan selebriti sek...               3  \n",
       "1  Asus memperkenalkan   ZenFone generasi keempat...               3  \n",
       "2  Dinas Pariwisata Provinsi Bengkulu kembali men...               2  \n",
       "3  Indonesia Corruption Watch ( ICW ) meminta Kom...               2  \n",
       "4  Jokowi memimpin upacara penurunan bendera . Us...               5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# Path dataset (sesuaikan dengan lokasi dataset Anda di Colab)\n",
    "DATASET_ROOT = './indosum'\n",
    "\n",
    "# Buat folder jika dataset belum ada\n",
    "if not os.path.exists(DATASET_ROOT):\n",
    "    os.makedirs(DATASET_ROOT)\n",
    "\n",
    "# Pastikan file dataset diunggah ke folder ini sebelum menjalankan kode\n",
    "files_id_dir = os.listdir(DATASET_ROOT)\n",
    "train_files = []\n",
    "\n",
    "for filename in files_id_dir:\n",
    "    if 'train' in filename:\n",
    "        train_files.append(filename)\n",
    "        \n",
    "# Fungsi untuk memuat data JSON Lines\n",
    "def load_file_to_json_list(filename):\n",
    "    file = os.path.join(DATASET_ROOT, filename)\n",
    "\n",
    "    data = []\n",
    "    with open(file, 'r') as f:\n",
    "        # Read the entire file content\n",
    "        file_content = f.read()\n",
    "        \n",
    "        # Split the content into individual JSON objects\n",
    "        json_list = file_content.splitlines() \n",
    "        \n",
    "        for json_str in tqdm(json_list, desc=f'Loading data {filename}'):\n",
    "            # Skip empty lines\n",
    "            if json_str.strip(): \n",
    "                try:\n",
    "                    d = json.loads(json_str)\n",
    "                    data.append(d)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    print(f\"Problematic JSON string: {json_str}\")\n",
    "                    # You might want to handle the error, e.g., skip the line or try to fix the JSON\n",
    "                    \n",
    "    return data\n",
    "\n",
    "# Fungsi untuk memproses label menjadi string JSON\n",
    "def label_to_dict_str(label_list):\n",
    "    label_dict = {}  # key = paragraph_id : value = label list \n",
    "    for i, label in enumerate(label_list[:]):\n",
    "        label_dict[i] = label\n",
    "\n",
    "    json_str = json.dumps(label_dict)\n",
    "    num = len(label_dict)\n",
    "    return json_str, num\n",
    "\n",
    "# Fungsi untuk memproses paragraph menjadi string JSON\n",
    "def paragraph_to_dict_str(paragraph_list):\n",
    "    paragraph_dict = {}  # key = paragraph_id : value = paragraph list \n",
    "    for i, paragraph in enumerate(paragraph_list):\n",
    "        new_paragraph = []\n",
    "        for sentence in paragraph:\n",
    "            sentence = ' '.join(sentence)\n",
    "            new_paragraph.append(sentence)\n",
    "        paragraph_dict[i] = new_paragraph\n",
    "\n",
    "    json_str = json.dumps(paragraph_dict)\n",
    "    num = len(paragraph_dict)\n",
    "    return json_str, num\n",
    "    \n",
    "# Fungsi untuk mengubah paragraf menjadi string teks\n",
    "def paragraph_to_text(raw_paragraph_list):\n",
    "    new_paragraph_list = []\n",
    "    for i, paragraph in enumerate(raw_paragraph_list):\n",
    "        paragraph_list = []\n",
    "        for sentence in paragraph:\n",
    "            sentence = ' '.join(sentence)\n",
    "            paragraph_list.append(sentence)\n",
    "\n",
    "        new_paragraph = ' '.join(paragraph_list)\n",
    "        new_paragraph_list.append(new_paragraph)\n",
    "\n",
    "    paragraph_str = ' '.join(new_paragraph_list)\n",
    "    return paragraph_str\n",
    "\n",
    "# Fungsi untuk memproses summary menjadi string JSON\n",
    "def summary_to_dict_str(summary_list):\n",
    "    summary_dict = {}  # key = summary_id : value = summary sentence \n",
    "    for i, summary in enumerate(summary_list):\n",
    "        summary_dict[i] = ' '.join(summary)\n",
    "\n",
    "    json_str = json.dumps(summary_dict)\n",
    "    num = len(summary_dict)\n",
    "    return json_str, num\n",
    "# Fungsi untuk mengubah summary menjadi string teks\n",
    "def summary_to_text(raw_summary_list):\n",
    "    summary_list = []\n",
    "    for i, summary in enumerate(raw_summary_list):\n",
    "        summary_list.append(' '.join(summary))\n",
    "\n",
    "    summary_str = ' '.join(summary_list)\n",
    "    return summary_str\n",
    "\n",
    "# Fungsi untuk mengubah data JSON\n",
    "def alter_json_data(json_list_data, filename=''):\n",
    "    new_json_list = []\n",
    "    for json_data in tqdm(json_list_data, desc=f'Altering json data {filename}'):\n",
    "        json_data = json_data.copy()\n",
    "        json_data['gold_labels'], _ = label_to_dict_str(json_data['gold_labels'])\n",
    "        json_data['news_text'] = paragraph_to_text(json_data['paragraphs'])\n",
    "        json_data['paragraphs'], num_paragraph = paragraph_to_dict_str(json_data['paragraphs'])\n",
    "        json_data['num_of_paragraphs'] = num_paragraph\n",
    "        json_data['summary_text'] = summary_to_text(json_data['summary'])\n",
    "        json_data['summary'], num_summary = summary_to_dict_str(json_data['summary'])\n",
    "        json_data['num_of_summary'] = num_summary\n",
    "\n",
    "        new_json_list.append(json_data)\n",
    "    \n",
    "    return new_json_list\n",
    "\n",
    "# Fungsi untuk membuat dataset dari JSON Lines\n",
    "def create_dataset(jsonl):\n",
    "    header = list(jsonl[0].keys())\n",
    "    dataset_list = []\n",
    "    for json_data in jsonl:\n",
    "        row = []\n",
    "        for h in header:\n",
    "            row.append(json_data[h])\n",
    "        dataset_list.append(row)\n",
    "    \n",
    "    return header, dataset_list\n",
    "\n",
    "# Fungsi untuk membuat dataset dari file JSON Lines\n",
    "def create_dataset_from_files(file_list):\n",
    "    df_header = None\n",
    "    dataset_list = []\n",
    "    for filename in file_list:\n",
    "        json_l = load_file_to_json_list(filename)\n",
    "        new_json_l = alter_json_data(json_l, filename)\n",
    "        header, dataset_part = create_dataset(new_json_l)\n",
    "        \n",
    "        if not df_header: df_header = header\n",
    "        dataset_list.extend(dataset_part)\n",
    "        \n",
    "    df_full = pd.DataFrame().from_records(dataset_list)\n",
    "    df_full = df_full.rename(columns=dict(enumerate(header)))\n",
    "    return df_full\n",
    "\n",
    "# Proses hanya data train\n",
    "df_train = create_dataset_from_files(train_files)\n",
    "\n",
    "# Tampilkan hasil\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deap\n",
      "  Downloading deap-1.4.1.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "     ----------------------------- ---------- 0.8/1.1 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.1/1.1 MB 5.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\arief m\\documents\\belajar\\semester 5\\nlp\\project1\\project1\\lib\\site-packages (from deap) (1.26.4)\n",
      "Building wheels for collected packages: deap\n",
      "  Building wheel for deap (setup.py): started\n",
      "  Building wheel for deap (setup.py): finished with status 'done'\n",
      "  Created wheel for deap: filename=deap-1.4.1-cp311-cp311-win_amd64.whl size=108753 sha256=71b1428c01dc0b139acee59269509663b40943a28ebd551fae1e9fe92e008871\n",
      "  Stored in directory: c:\\users\\arief m\\appdata\\local\\pip\\cache\\wheels\\f8\\64\\b8\\65eacfbff3024ae2e2beb22e691d5c8abb89fbd863b8049b5f\n",
      "Successfully built deap\n",
      "Installing collected packages: deap\n",
      "Successfully installed deap-1.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (C:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (C:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (C:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install deap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "c:\\Users\\Arief M\\Documents\\belajar\\Semester 5\\NLP\\Project1\\project1\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mulai Genetic Algorithm...\n",
      "-- Generasi 1 --\n",
      "-- Generasi 2 --\n",
      "-- Generasi 3 --\n",
      "-- Generasi 4 --\n",
      "-- Generasi 5 --\n",
      "Individu terbaik: [108.42348340677029, 4.0942440229413855, 1.8424340179116698, 1.6747165278030955]\n",
      "Skor ROUGE terbaik: 0.7556036429596136\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools, algorithms\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "# Load model dan tokenizer\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"panggi/t5-base-indonesian-summarization-cased\")\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"panggi/t5-base-indonesian-summarization-cased\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "t5_model = t5_model.to(device)\n",
    "\n",
    "# Fungsi untuk menghasilkan ringkasan\n",
    "def generate_summary(article, max_length=150, num_beams=4, repetition_penalty=2.5, length_penalty=1.0):\n",
    "    input_ids = t5_tokenizer.encode(article, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "    summary_ids = t5_model.generate(\n",
    "        input_ids,\n",
    "        max_length=int(max_length),\n",
    "        num_beams=int(num_beams),\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        length_penalty=length_penalty,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        use_cache=True\n",
    "    )\n",
    "    return t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# **Dataset tetap dari kode awal**\n",
    "max_length = df_train['summary_text'].str.len().max()\n",
    "max_steps = 100  # Batasi data\n",
    "df_train_sample = df_train.head(max_steps)\n",
    "\n",
    "# Fungsi Evaluasi dengan ROUGE\n",
    "rouge = load('rouge')\n",
    "\n",
    "def evaluate_summary(params):\n",
    "    max_length, num_beams, repetition_penalty, length_penalty = params\n",
    "    references = df_train_sample['summary_text'].values\n",
    "    predictions = []\n",
    "    for _, row in df_train_sample.iterrows():\n",
    "        try:\n",
    "            pred = generate_summary(\n",
    "                row['news_text'],\n",
    "                max_length=max_length,\n",
    "                num_beams=num_beams,\n",
    "                repetition_penalty=repetition_penalty,\n",
    "                length_penalty=length_penalty\n",
    "            )\n",
    "        except Exception as e:\n",
    "            pred = \"\"\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Evaluasi ROUGE\n",
    "    results = rouge.compute(references=references, predictions=predictions)\n",
    "    return results['rouge1']  # Skor ROUGE-1 digunakan sebagai fitness function\n",
    "\n",
    "# **Genetic Algorithm Setup**\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))  # Maximizing ROUGE\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_max_length\", np.random.uniform, 50, 150)  # Batasan panjang maksimum ringkasan\n",
    "toolbox.register(\"attr_num_beams\", np.random.randint, 2, 8)             # Beam search\n",
    "toolbox.register(\"attr_repetition_penalty\", np.random.uniform, 1.0, 3.0)  # Penalti pengulangan\n",
    "toolbox.register(\"attr_length_penalty\", np.random.uniform, 0.5, 2.0)      # Penalti panjang\n",
    "\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_max_length, toolbox.attr_num_beams,\n",
    "                  toolbox.attr_repetition_penalty, toolbox.attr_length_penalty), n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate_summary)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.5, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# Jalankan GA\n",
    "population = toolbox.population(n=10)  # Populasi awal\n",
    "NGEN = 5  # Jumlah generasi\n",
    "CXPB, MUTPB = 0.5, 0.2  # Probabilitas crossover dan mutasi\n",
    "\n",
    "print(\"Mulai Genetic Algorithm...\")\n",
    "for gen in range(NGEN):\n",
    "    print(f\"-- Generasi {gen + 1} --\")\n",
    "    # Evaluasi semua individu\n",
    "    fitnesses = list(map(toolbox.evaluate, population))\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        ind.fitness.values = (fit,)\n",
    "    \n",
    "    # Seleksi\n",
    "    offspring = toolbox.select(population, len(population))\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Crossover dan Mutasi\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if np.random.rand() < CXPB:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values, child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if np.random.rand() < MUTPB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # Evaluasi ulang individu dengan fitness kosong\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = (fit,)\n",
    "\n",
    "    # Ganti populasi dengan offspring baru\n",
    "    population[:] = offspring\n",
    "\n",
    "# Ambil hasil terbaik\n",
    "best_ind = tools.selBest(population, 1)[0]\n",
    "print(f\"Individu terbaik: {best_ind}\")\n",
    "print(f\"Skor ROUGE terbaik: {best_ind.fitness.values[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
